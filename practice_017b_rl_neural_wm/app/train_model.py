"""Train the neural world model on collected transitions.

Loads transitions from disk (generated by data_collection.py), splits into
train/validation, and trains the WorldModel via supervised learning.

Usage:
    uv run python -m app.data_collection   # first, collect data
    uv run python -m app.train_model        # then, train the model
"""

from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch
from torch.optim import Adam

from app.config import DATA_COLLECTION, ENV, WORLD_MODEL
from app.data_collection import load_buffer
from app.replay_buffer import ReplayBuffer, TransitionBatch
from app.world_model import WorldModel


def split_buffer(
    buffer: ReplayBuffer,
    validation_split: float,
) -> tuple[TransitionBatch, TransitionBatch]:
    """Split buffer data into training and validation sets."""
    batch = buffer.all_data()
    n = len(batch.states)
    indices = np.random.permutation(n)

    val_size = int(n * validation_split)
    val_idx = indices[:val_size]
    train_idx = indices[val_size:]

    def select(idx: np.ndarray) -> TransitionBatch:
        return TransitionBatch(
            states=batch.states[idx],
            actions=batch.actions[idx],
            rewards=batch.rewards[idx],
            next_states=batch.next_states[idx],
            dones=batch.dones[idx],
        )

    return select(train_idx), select(val_idx)


def to_tensors(
    batch: TransitionBatch,
    device: torch.device,
) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
    """Convert a TransitionBatch to PyTorch tensors on the given device."""
    return (
        torch.tensor(batch.states, dtype=torch.float32, device=device),
        torch.tensor(batch.actions, dtype=torch.long, device=device),
        torch.tensor(batch.rewards, dtype=torch.float32, device=device),
        torch.tensor(batch.next_states, dtype=torch.float32, device=device),
        torch.tensor(batch.dones, dtype=torch.float32, device=device),
    )


def train_world_model(
    model: WorldModel,
    train_data: TransitionBatch,
    val_data: TransitionBatch,
    epochs: int = WORLD_MODEL.train_epochs,
    batch_size: int = WORLD_MODEL.batch_size,
    learning_rate: float = WORLD_MODEL.learning_rate,
) -> dict[str, list[float]]:
    """Train the world model and return loss history.

    Args:
        model: The WorldModel to train.
        train_data: Training transitions.
        val_data: Validation transitions.
        epochs: Number of training epochs.
        batch_size: Mini-batch size.
        learning_rate: Adam learning rate.

    Returns:
        Dictionary with keys "train_loss" and "val_loss", each a list of
        per-epoch average losses.
    """
    device = next(model.parameters()).device
    optimizer = Adam(model.parameters(), lr=learning_rate)

    train_tensors = to_tensors(train_data, device)
    val_tensors = to_tensors(val_data, device)

    n_train = len(train_data.states)
    history: dict[str, list[float]] = {"train_loss": [], "val_loss": []}

    for epoch in range(epochs):
        # --- Training ---
        model.train()
        epoch_losses: list[float] = []

        # TODO(human): Implement the training loop for one epoch.
        #
        # Steps:
        #   1. Generate a random permutation of indices [0, n_train)
        #   2. Iterate over mini-batches (slice indices by batch_size):
        #      a. Extract the batch: states, actions, rewards, next_states, dones
        #         from train_tensors using the batch indices
        #      b. Forward pass: pred_state, pred_reward, pred_done = model(states, actions)
        #      c. Compute loss: total_loss, loss_dict = model.compute_loss(
        #             pred_state, pred_reward, pred_done,
        #             next_states, rewards, dones
        #         )
        #      d. Backprop: optimizer.zero_grad(), total_loss.backward(), optimizer.step()
        #      e. Append loss_dict["total"] to epoch_losses
        #   3. After all batches, compute mean training loss for this epoch
        #
        # Hint: Use torch.randperm(n_train) for the permutation.
        raise NotImplementedError("TODO(human): Implement mini-batch training loop")

        avg_train_loss = float(np.mean(epoch_losses))
        history["train_loss"].append(avg_train_loss)

        # --- Validation ---
        val_loss = evaluate_model(model, val_tensors)
        history["val_loss"].append(val_loss)

        if (epoch + 1) % 10 == 0 or epoch == 0:
            print(f"Epoch {epoch+1:3d}/{epochs}  train={avg_train_loss:.4f}  val={val_loss:.4f}")

    return history


def evaluate_model(
    model: WorldModel,
    tensors: tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor],
) -> float:
    """Evaluate model on a dataset and return average total loss.

    Args:
        model: The trained WorldModel.
        tensors: Tuple of (states, actions, rewards, next_states, dones) tensors.

    Returns:
        Average total loss as a float.
    """
    # TODO(human): Implement validation evaluation.
    #
    # Steps:
    #   1. Set model to eval mode: model.eval()
    #   2. Use torch.no_grad() context manager (no gradients needed)
    #   3. Forward pass on the ENTIRE validation set (no batching needed for eval)
    #   4. Compute loss using model.compute_loss(...)
    #   5. Return the total loss as a float
    #
    # Note: Unpack tensors as: states, actions, rewards, next_states, dones = tensors
    raise NotImplementedError("TODO(human): Implement validation evaluation")


def plot_training_curves(history: dict[str, list[float]], save_path: str) -> None:
    """Plot and save training/validation loss curves."""
    fig, ax = plt.subplots(figsize=(8, 5))
    epochs = range(1, len(history["train_loss"]) + 1)

    ax.plot(epochs, history["train_loss"], label="Train Loss", linewidth=2)
    ax.plot(epochs, history["val_loss"], label="Val Loss", linewidth=2, linestyle="--")
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.set_title("World Model Training Curve")
    ax.legend()
    ax.grid(True, alpha=0.3)

    Path(save_path).parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(save_path, dpi=150, bbox_inches="tight")
    plt.close(fig)
    print(f"Training curve saved to {save_path}")


def main() -> None:
    """Load data, train world model, save results."""
    if not Path(DATA_COLLECTION.save_path).exists():
        print(f"No data found at {DATA_COLLECTION.save_path}.")
        print("Run `uv run python -m app.data_collection` first.")
        return

    buffer = load_buffer(DATA_COLLECTION.save_path)
    train_data, val_data = split_buffer(buffer, WORLD_MODEL.validation_split)
    print(f"Train: {len(train_data.states)} transitions, Val: {len(val_data.states)} transitions")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    model = WorldModel().to(device)
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

    history = train_world_model(model, train_data, val_data)

    # Save the trained model
    save_dir = Path("checkpoints")
    save_dir.mkdir(parents=True, exist_ok=True)
    torch.save(model.state_dict(), save_dir / "world_model.pt")
    print(f"Model saved to {save_dir / 'world_model.pt'}")

    plot_training_curves(history, "plots/training_curve.png")


if __name__ == "__main__":
    main()
